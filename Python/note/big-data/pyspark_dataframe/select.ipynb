{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b815b78-e1dc-4fb5-af94-bd42b84210c1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 05:06:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/01/20 05:06:34 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/01/20 05:06:34 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47947a41-9178-4103-b4b0-1f96519d2306",
   "metadata": {},
   "source": [
    "## Read operation\n",
    "\n",
    "Suppose we have a csv file, we can use `spark.read.csv()` like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9e9631-683b-4b6d-b918-7f1f4419f6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "| john| 33|\n",
      "| jack| 26|\n",
      "|derry| 28|\n",
      "| mary| 64|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvFile = spark.read.csv(\"sample.csv\", header=True)\n",
    "csvFile.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70184ea-f64d-463d-a4ac-25f10be93b22",
   "metadata": {},
   "source": [
    "### Read from plain text and process the file\n",
    "\n",
    "This is plain text file, we're going to process this file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d8dbf4-b54e-4c93-90aa-eec88c63bd76",
   "metadata": {},
   "source": [
    "## Select\n",
    "\n",
    "PySpark accepts different types of args\n",
    "\n",
    "`select(columns)`\n",
    "\n",
    "columns type:\n",
    "- `string`\n",
    "- `pyspark.sql.column.Column`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40eb26cf-5ce3-4a97-a65c-7be08591f6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "| john| 33|\n",
      "| jack| 26|\n",
      "|derry| 28|\n",
      "| mary| 64|\n",
      "+-----+---+\n",
      "\n",
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "| john| 33|\n",
      "| jack| 26|\n",
      "|derry| 28|\n",
      "| mary| 64|\n",
      "+-----+---+\n",
      "\n",
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "| john| 33|\n",
      "| jack| 26|\n",
      "|derry| 28|\n",
      "| mary| 64|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "csvFile.select(\"name\", \"age\").show()\n",
    "csvFile.select(csvFile.name, csvFile.age).show()\n",
    "csvFile.select(col(\"name\"), col(\"age\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9bb1d7-4c9e-4881-a4bd-1616a8539ac5",
   "metadata": {},
   "source": [
    "These 2 actually are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b84dc23-0349-4f4f-a439-6d2ee20735fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(csvFile.name) == type(col(\"name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e654de-505e-434e-b8ff-8a09370c4fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "| name|(age + 20)|\n",
      "+-----+----------+\n",
      "| john|      53.0|\n",
      "| jack|      46.0|\n",
      "|derry|      48.0|\n",
      "| mary|      84.0|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvFile.select(csvFile['name'], csvFile['age'] + 20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d15c063a-9f5f-4494-851c-ca947159723b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|john| 33|\n",
      "|mary| 64|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvFile.filter(csvFile['age'] > 30).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f804e94-5b47-4c23-a118-d71d14d65dc5",
   "metadata": {},
   "source": [
    "## Create a view and access by `spark.sql()`\n",
    "\n",
    "> The engine works for sql and dataframe is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e71a3718-7bcb-4c3e-82d3-b39052549490",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile.createTempView(\"people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88a67e12-1539-4a34-a962-e51b1c2e7edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "| john| 33|\n",
      "| jack| 26|\n",
      "|derry| 28|\n",
      "| mary| 64|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from people\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3d9a2c-6ecf-4aaa-a2bd-86cd0fd8729e",
   "metadata": {},
   "source": [
    "### Nested data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b2cc235-0a79-4d50-b282-16fbe0497c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------+\n",
      "|                name|      state|gender|\n",
      "+--------------------+-----------+------+\n",
      "| {Rame, null, Gupta}|  Rajasthan|     M|\n",
      "|     {Anita, Garg, }|      Delhi|     F|\n",
      "| {Pooja, , Aggarwal}|      Delhi|     F|\n",
      "|{Saurabh, Anne, J...|      Jammu|     M|\n",
      "|{Shahrukh, Khan, ...|Maharashtra|     M|\n",
      "|{Salman, Gupta, W...|      Delhi|     M|\n",
      "+--------------------+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_data1 = [((\"Rame\",None,\"Gupta\"),\"Rajasthan\",\"M\"),\n",
    "        ((\"Anita\",\"Garg\",\"\"),\"Delhi\",\"F\"),\n",
    "        ((\"Pooja\",\"\",\"Aggarwal\"),\"Delhi\",\"F\"),\n",
    "        ((\"Saurabh\",\"Anne\",\"Jones\"),\"Jammu\",\"M\"),\n",
    "        ((\"Shahrukh\",\"Khan\",\"Brown\"),\"Maharashtra\",\"M\"),\n",
    "        ((\"Salman\",\"Gupta\",\"Williams\"),\"Delhi\",\"M\")]\n",
    "\n",
    "sample_schema = StructType([\n",
    "    StructField('name', StructType([\n",
    "         StructField('firstname', StringType(), True),\n",
    "         StructField('middlename', StringType(), True),\n",
    "         StructField('lastname', StringType(), True)\n",
    "         ])),\n",
    "     StructField('state', StringType(), True),\n",
    "     StructField('gender', StringType(), True)\n",
    "     ])\n",
    "nested_df = spark.createDataFrame(data = sample_data1, schema = sample_schema)\n",
    "nested_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a6986f6-662f-4eb0-b310-f4e83c03ffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|firstname|\n",
      "+---------+\n",
      "|     Rame|\n",
      "|    Anita|\n",
      "|    Pooja|\n",
      "|  Saurabh|\n",
      "| Shahrukh|\n",
      "|   Salman|\n",
      "+---------+\n",
      "\n",
      "+---------+----------+--------+\n",
      "|firstname|middlename|lastname|\n",
      "+---------+----------+--------+\n",
      "|     Rame|      null|   Gupta|\n",
      "|    Anita|      Garg|        |\n",
      "|    Pooja|          |Aggarwal|\n",
      "|  Saurabh|      Anne|   Jones|\n",
      "| Shahrukh|      Khan|   Brown|\n",
      "|   Salman|     Gupta|Williams|\n",
      "+---------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nested_df.select(\"name.firstname\").show()\n",
    "nested_df.select(\"name.*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3312da5-1450-4426-a20c-b9862512e54d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
